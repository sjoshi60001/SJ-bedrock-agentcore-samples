{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba51a29-a566-4b5a-97f0-10e634567e40",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Transform OpenAPI APIs into MCP tools using Bedrock AgentCore Gateway\n",
    "\n",
    "## Overview\n",
    "Customers can bring OpenAPI spec in JSON or YAML and transform the apis into MCP tools using Bedrock AgentCore Gateway. \n",
    "\n",
    "The Gateway workflow involves the following steps to connect your agents to external tools:\n",
    "* **Create the tools for your Gateway** - Define your tools using schemas such as OpenAPI specifications for REST APIs. The OpenAPI specifications are then parsed by Amazon Bedrock AgentCore for creating the Gateway.\n",
    "* **Create a Gateway endpoint** - Create the gateway that will serve as the MCP entry point with inbound authentication.\n",
    "* **Add targets to your Gateway** - Configure the OpenAPI targets that define how the gateway routes requests to specific tools. All the APIs that part of OpenAPI file will become an MCP-compatible tool, and will be made available through your Gateway endpoint URL. Configure outbound authorization for each OpenAPI Gateway target. \n",
    "* **Update your agent code** - Connect your agent to the Gateway endpoint to access all configured tools through the unified MCP interface.\n",
    "\n",
    "![How does it work](images/openapi-gateway-apikey.png)\n",
    "\n",
    "### Tutorial Details\n",
    "\n",
    "\n",
    "| Information          | Details                                                   |\n",
    "|:---------------------|:----------------------------------------------------------|\n",
    "| Tutorial type        | Interactive                                               |\n",
    "| AgentCore components | AgentCore Gateway, AgentCore Identity                     |\n",
    "| Agentic Framework    | Strands Agents                                            |\n",
    "| Gateway Target type  | OpenAPI                                                   |\n",
    "| Agent                | Finance Agent                                        |\n",
    "| Inbound Auth IdP     | Amazon Cognito                                            |\n",
    "| Outbound Auth        | API Key                                                   |\n",
    "| LLM model            | Anthropic Claude Sonnet 3.7 Inference profile              |\n",
    "| Tutorial components  | Creating AgentCore Gateway and Invoking AgentCore Gateway |\n",
    "| Tutorial vertical    | Cross-vertical                                            |\n",
    "| Example complexity   | Easy                                                      |\n",
    "| SDK used             | boto3 , AgentCore starter kit                             |\n",
    "\n",
    "In the first part of the tutorial we will create some AmazonCore Gateway targets\n",
    "\n",
    "### Tutorial Architecture\n",
    "In this tutorial we will transform operations defined in OpenAPI yaml/json file into MCP tools and host it in Bedrock AgentCore Gateway.\n",
    "The solution uses Strands Agent using Amazon Bedrock models.\n",
    "In our example we will use a strands agent which will invoke Agentcore gateway to use the tools exposed by Intrinio API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5362e1ad-f027-4452-a8d9-0b861c0115c2",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To execute this tutorial you will need:\n",
    "* Jupyter notebook (Python kernel)\n",
    "* uv\n",
    "* AWS credentials\n",
    "* Amazon Cognito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17e1d70-9a76-42ce-b1ac-1c3a0bf4d12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.2 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "dash 2.18.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-table==5.0.0, which is not installed.\n",
      "jupyter-ai 2.29.1 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\n",
      "aiobotocore 2.20.0 requires botocore<1.36.24,>=1.36.20, but you have botocore 1.40.29 which is incompatible.\n",
      "amazon-sagemaker-jupyter-ai-q-developer 1.0.17 requires numpy<=2.0.1, but you have numpy 2.3.2 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.4 requires numpy<2, but you have numpy 2.3.2 which is incompatible.\n",
      "autogluon-common 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.3.2 which is incompatible.\n",
      "autogluon-common 1.2 requires pandas<2.3.0,>=2.0.0, but you have pandas 2.3.2 which is incompatible.\n",
      "autogluon-common 1.2 requires psutil<7.0.0,>=5.7.3, but you have psutil 7.0.0 which is incompatible.\n",
      "autogluon-core 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.3.2 which is incompatible.\n",
      "autogluon-core 1.2 requires pandas<2.3.0,>=2.0.0, but you have pandas 2.3.2 which is incompatible.\n",
      "autogluon-features 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.3.2 which is incompatible.\n",
      "autogluon-features 1.2 requires pandas<2.3.0,>=2.0.0, but you have pandas 2.3.2 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.25.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires nltk<3.9,>=3.4.5, but you have nltk 3.9.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.3.2 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires pandas<2.3.0,>=2.0.0, but you have pandas 2.3.2 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.51.1 which is incompatible.\n",
      "autogluon-tabular 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.3.2 which is incompatible.\n",
      "autogluon-tabular 1.2 requires pandas<2.3.0,>=2.0.0, but you have pandas 2.3.2 which is incompatible.\n",
      "autogluon-timeseries 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.3.2 which is incompatible.\n",
      "autogluon-timeseries 1.2 requires pandas<2.3.0,>=2.0.0, but you have pandas 2.3.2 which is incompatible.\n",
      "autogluon-timeseries 1.2 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.51.1 which is incompatible.\n",
      "catboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.3.2 which is incompatible.\n",
      "dash 2.18.1 requires Flask<3.1,>=1.0.4, but you have flask 3.1.0 which is incompatible.\n",
      "dash 2.18.1 requires Werkzeug<3.1, but you have werkzeug 3.1.3 which is incompatible.\n",
      "fastapi 0.115.12 requires starlette<0.47.0,>=0.40.0, but you have starlette 0.47.3 which is incompatible.\n",
      "flake8 7.1.2 requires pycodestyle<2.13.0,>=2.12.0, but you have pycodestyle 2.14.0 which is incompatible.\n",
      "gluonts 0.16.1 requires numpy<2.2,>=1.16, but you have numpy 2.3.2 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires psutil~=5.9, but you have psutil 7.0.0 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires pytz<=2024.2,>=2023.3, but you have pytz 2025.2 which is incompatible.\n",
      "langchain-aws 0.2.10 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.3.2 which is incompatible.\n",
      "langchain-core 0.3.51 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "lightning 2.5.1 requires packaging<25.0,>=20.0, but you have packaging 25.0 which is incompatible.\n",
      "mdit-py-plugins 0.4.2 requires markdown-it-py<4.0.0,>=1.0.0, but you have markdown-it-py 4.0.0 which is incompatible.\n",
      "mlflow 2.20.4 requires packaging<25, but you have packaging 25.0 which is incompatible.\n",
      "mlflow-skinny 2.20.4 requires packaging<25, but you have packaging 25.0 which is incompatible.\n",
      "sagemaker 2.228.0 requires attrs<24,>=23.1.0, but you have attrs 25.3.0 which is incompatible.\n",
      "sagemaker 2.228.0 requires importlib-metadata<7.0,>=1.4.0, but you have importlib-metadata 8.7.0 which is incompatible.\n",
      "sagemaker 2.228.0 requires numpy<2.0,>=1.9.0, but you have numpy 2.3.2 which is incompatible.\n",
      "sagemaker 2.228.0 requires protobuf<5.0,>=3.12, but you have protobuf 5.29.5 which is incompatible.\n",
      "spacy 3.8.5 requires thinc<8.4.0,>=8.3.4, but you have thinc 8.3.2 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.2 which is incompatible.\n",
      "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.5 which is incompatible.\n",
      "awscli 1.42.22 requires botocore==1.40.22, but you have botocore 1.40.29 which is incompatible.\n",
      "awscli 1.42.22 requires s3transfer<0.14.0,>=0.13.0, but you have s3transfer 0.14.0 which is incompatible.\n",
      "aws-opentelemetry-distro 0.10.1 requires opentelemetry-api==1.33.1, but you have opentelemetry-api 1.37.0 which is incompatible.\n",
      "aws-opentelemetry-distro 0.10.1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "aws-opentelemetry-distro 0.10.1 requires opentelemetry-sdk==1.33.1, but you have opentelemetry-sdk 1.37.0 which is incompatible.\n",
      "opentelemetry-instrumentation-wsgi 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-wsgi 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-urllib3 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-urllib3 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-urllib 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-urllib 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-tortoiseorm 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-tortoiseorm 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-tornado 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-tornado 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-system-metrics 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-sqlalchemy 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-sqlalchemy 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-requests 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-requests 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-remoulade 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-remoulade 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-redis 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-redis 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-pymongo 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-pymongo 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-pymemcache 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-pymemcache 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-pika 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-logging 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-kafka-python 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-kafka-python 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-jinja2 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-httpx 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-httpx 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-grpc 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-grpc 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-elasticsearch 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-elasticsearch 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-dbapi 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-dbapi 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-confluent-kafka 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-celery 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-celery 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-cassandra 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-cassandra 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-botocore 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-botocore 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-boto3sqs 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-boto3sqs 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-boto 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-boto 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-aws-lambda 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-aws-lambda 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-asyncpg 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-asyncpg 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-asgi 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-asgi 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-aiohttp-client 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-aiohttp-client 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-aio-pika 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.33.1 requires opentelemetry-sdk~=1.33.1, but you have opentelemetry-sdk 1.37.0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-grpc 1.33.1 requires opentelemetry-sdk~=1.33.1, but you have opentelemetry-sdk 1.37.0 which is incompatible.\n",
      "opentelemetry-distro 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-starlette 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-starlette 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-sqlite3 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-pyramid 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-pyramid 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-pymysql 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-psycopg2 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-mysqlclient 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-mysql 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-flask 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-flask 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-fastapi 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-fastapi 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-falcon 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-falcon 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-django 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-django 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-aiopg 0.54b1 requires opentelemetry-instrumentation==0.54b1, but you have opentelemetry-instrumentation 0.58b0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall -U -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e6248d-b740-418b-ae0d-c0a9623e43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some environment variables\n",
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION'] = os.environ.get('AWS_REGION', 'us-east-1')\n",
    "BUCKET_NAME='agentcore-gateway-251267873559-us-west-2'\n",
    "FILE_NAME='intrinio-api-schema.json'\n",
    "OBJECT_KEY='openapi_3_spec.json'\n",
    "API_KEY='IntrinioKeyFromProvider'\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca94412-7337-4293-ab74-aa2e77507fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the directory of the current script\n",
    "if '__file__' in globals():\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_dir = os.getcwd()  # Fallback if __file__ is not defined (e.g., Jupyter)\n",
    "\n",
    "# Navigate to the directory containing utils.py (one level up)\n",
    "utils_dir = os.path.abspath(os.path.join(current_dir, '../..'))\n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.insert(0, utils_dir)\n",
    "\n",
    "# Now you can import utils\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f4cb2b-14b0-4171-982a-19a1ed4e8ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role already exists -- deleting and creating it again\n",
      "policies: {'PolicyNames': ['AgentCorePolicy'], 'IsTruncated': False, 'ResponseMetadata': {'RequestId': '1122da1f-02db-425e-b54a-9df2c0c3443a', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Fri, 12 Sep 2025 16:14:45 GMT', 'x-amzn-requestid': '1122da1f-02db-425e-b54a-9df2c0c3443a', 'content-type': 'text/xml', 'content-length': '380'}, 'RetryAttempts': 0}}\n",
      "deleting agentcore-sample-APIgateway-role\n",
      "recreating agentcore-sample-APIgateway-role\n",
      "attaching role policy agentcore-sample-APIgateway-role\n",
      "Agentcore gateway role ARN:  arn:aws:iam::251267873559:role/agentcore-sample-APIgateway-role\n"
     ]
    }
   ],
   "source": [
    "#### Create an IAM role for the Gateway to assume\n",
    "import utils\n",
    "\n",
    "agentcore_gateway_iam_role = utils.create_agentcore_gateway_role(\"sample-APIgateway\")\n",
    "print(\"Agentcore gateway role ARN: \", agentcore_gateway_iam_role['Role']['Arn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a63450-7fb9-42fc-ab4f-3d86c27bb2f8",
   "metadata": {},
   "source": [
    "# Create the Cognito Authorizer & Agentcore Gateway "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e62c70c-3ebc-4aaa-bcf7-b9ad0d433962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:14:52,943 - bedrock_agentcore.gateway - INFO - Starting EZ Auth setup: Creating Cognito resources...\n",
      "2025-09-12 16:14:54,257 - bedrock_agentcore.gateway - INFO -   ✓ Created User Pool: us-west-2_3tNvIsTvw\n",
      "2025-09-12 16:14:55,348 - bedrock_agentcore.gateway - INFO -   ✓ Created domain: agentcore-27cdb884\n",
      "2025-09-12 16:14:55,349 - bedrock_agentcore.gateway - INFO -   ⏳ Waiting for domain to be available...\n",
      "2025-09-12 16:14:55,421 - bedrock_agentcore.gateway - INFO -   ✓ Domain is active\n",
      "2025-09-12 16:14:55,683 - bedrock_agentcore.gateway - INFO -   ✓ Created resource server: my-gateway\n",
      "2025-09-12 16:14:55,941 - bedrock_agentcore.gateway - INFO -   ✓ Created client: 5c0atu732s64l0cv163qeollin\n",
      "2025-09-12 16:14:55,942 - bedrock_agentcore.gateway - INFO -   ⏳ Waiting for DNS propagation of domain: agentcore-27cdb884.auth.us-west-2.amazoncognito.com\n",
      "2025-09-12 16:15:55,947 - bedrock_agentcore.gateway - INFO - ✓ EZ Auth setup complete!\n"
     ]
    }
   ],
   "source": [
    "from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient\n",
    "\n",
    "# Initialize the Gateway client\n",
    "client = GatewayClient(region_name=os.environ['AWS_DEFAULT_REGION'])\n",
    "\n",
    "# EZ Auth - automatically sets up Cognito OAuth\n",
    "cognito_result = client.create_oauth_authorizer_with_cognito(\"my-gateway\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16b020a-db1e-4d99-a7ae-37f73f0058da",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorizer_configuration = cognito_result[\"authorizer_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9894108a-eff2-401c-a23f-e169485f1e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:16:07,216 - bedrock_agentcore.gateway - INFO - Creating Gateway\n",
      "2025-09-12 16:16:07,624 - bedrock_agentcore.gateway - INFO - ✓ Created Gateway: arn:aws:bedrock-agentcore:us-west-2:251267873559:gateway/testgatewayce61ef79-z61nbl7wbr\n",
      "2025-09-12 16:16:07,625 - bedrock_agentcore.gateway - INFO -   Gateway URL: https://testgatewayce61ef79-z61nbl7wbr.gateway.bedrock-agentcore.us-west-2.amazonaws.com/mcp\n",
      "2025-09-12 16:16:07,626 - bedrock_agentcore.gateway - INFO -   Waiting for Gateway to be ready...\n",
      "2025-09-12 16:16:07,739 - bedrock_agentcore.gateway - INFO - \n",
      "✅Gateway is ready\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OAuth Credentials:\n",
      "  Client ID: 5c0atu732s64l0cv163qeollin\n",
      "  Scope: my-gateway/invoke\n"
     ]
    }
   ],
   "source": [
    "gateway = client.create_mcp_gateway(\n",
    "    # name=none, # the name of the Gateway - if you don't set one, one will be generated.\n",
    "    role_arn=agentcore_gateway_iam_role['Role']['Arn'], # the role arn that the Gateway will use - if you don't set one, one will be created.\n",
    "    authorizer_config=authorizer_configuration, # Variable from inbound authorization setup steps. Contains the OAuth authorizer details for authorizing callers to your Gateway (MCP only supports OAuth).\n",
    "    enable_semantic_search=True # enable semantic search.\n",
    "\n",
    ")\n",
    "print(f\"OAuth Credentials:\")\n",
    "print(f\"  Client ID: {cognito_result['client_info']['client_id']}\")\n",
    "print(f\"  Scope: {cognito_result['client_info']['scope']}\")\n",
    "gateway_id=gateway['gatewayId']\n",
    "gateway_url=gateway['gatewayUrl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1345c920-3921-40c7-9c00-110e8d02184b",
   "metadata": {},
   "source": [
    "# Transforming Intrinio Open APIs into MCP tools using Bedrock AgentCore Gateway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4765ddea-a86d-492e-90f9-ffb14e1b3b74",
   "metadata": {},
   "source": [
    "We will use Intrinio APIs to expose as MCP tools. We will use Intrinio API key to configure the credentials provider for creating the OpenAPI target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64caa620-02ec-424a-a8b9-eb00b39289bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (ValidationException) when calling the CreateApiKeyCredentialProvider operation: Credential provider with name: IntrinioAPIKey already exists\n",
      "('Egress Credentials provider ARN, '\n",
      " 'arn:aws:bedrock-agentcore:us-west-2:251267873559:token-vault/default/apikeycredentialprovider/IntrinioAPIKey')\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from pprint import pprint\n",
    "from botocore.config import Config\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "client = boto3.client('secretsmanager', region_name=os.environ['AWS_DEFAULT_REGION'])\n",
    "response = client.get_secret_value(SecretId=API_KEY)\n",
    "secret_dict = json.loads(response['SecretString'])\n",
    "secret_value = list(secret_dict.values())[0]\n",
    "acps = boto3.client(service_name=\"bedrock-agentcore-control\")\n",
    "\n",
    "try:\n",
    "    response= acps.create_api_key_credential_provider(\n",
    "        name=\"IntrinioAPIKey\",\n",
    "        apiKey=secret_value,  \n",
    "    )\n",
    "except Exception as e:\n",
    "\n",
    "    print(e)\n",
    "    \n",
    "\n",
    "    response = acps.get_api_key_credential_provider(\n",
    "        name=\"IntrinioAPIKey\"\n",
    "    )\n",
    "credentialProviderARN = response['credentialProviderArn']\n",
    "pprint(f\"Egress Credentials provider ARN, {credentialProviderARN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00592440-d261-445d-9792-d1a193888746",
   "metadata": {},
   "source": [
    "#### If you see an error as below\n",
    "#### \"An error occurred (ValidationException) when calling the CreateApiKeyCredentialProvider operation: Credential provider with #### name: IntrinioAPIKey already exists\n",
    "#### ('Egress Credentials provider ARN, '\n",
    "#### 'arn:aws:bedrock-agentcore:xxxxxxxxxx:token-vault/default/apikeycredentialprovider/IntrinioAPIKey')\"\n",
    "####  ignore the error. This means the credential provider is created by other users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b092f-be1d-4b31-abb7-1fb8cab887ef",
   "metadata": {},
   "source": [
    "# Create an OpenAPI target "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a76599-fbb2-4104-a3d5-5be3cde2e12d",
   "metadata": {},
   "source": [
    "#### We will use a S3 bucket to store the OpenAPI spec from Intrinio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a105be4e-ae05-4981-a609-01d410f66023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded object S3 URI: s3://agentcore-gateway-251267873559-us-west-2/openapi_3_spec.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "openapi_s3_uri = f's3://{BUCKET_NAME}/{OBJECT_KEY}'\n",
    "print(f'Uploaded object S3 URI: {openapi_s3_uri}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f371d-3118-4c7f-bb23-c90ab09e4284",
   "metadata": {},
   "source": [
    "#### Configure outbound auth and Create the gateway target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "629945ac-d1c3-49ae-92f7-4b0e0ef6d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gateway_client = boto3.client('bedrock-agentcore-control', region_name = os.environ['AWS_DEFAULT_REGION'])\n",
    "\n",
    "# S3 Uri for OpenAPI spec file\n",
    "Intrinio_openapi_s3_target_config = {\n",
    "    \"mcp\": {\n",
    "          \"openApiSchema\": {\n",
    "              \"s3\": {\n",
    "                  \"uri\": openapi_s3_uri\n",
    "              }\n",
    "          }\n",
    "      }\n",
    "}\n",
    "\n",
    "# API Key credentials provider configuration\n",
    "api_key_credential_config = [\n",
    "    {\n",
    "        \"credentialProviderType\" : \"API_KEY\", \n",
    "        \"credentialProvider\": {\n",
    "            \"apiKeyCredentialProvider\": {\n",
    "                    \"credentialParameterName\": \"api_key\", # Replace this with the name of the api key name expected by the respective API provider. For passing token in the header, use \"Authorization\"\n",
    "                    \"providerArn\": credentialProviderARN,\n",
    "                    \"credentialLocation\":\"QUERY_PARAMETER\", # Location of api key. Possible values are \"HEADER\" and \"QUERY_PARAMETER\".\n",
    "                    #\"credentialPrefix\": \" \" # Prefix for the token. Valid values are \"Basic\". Applies only for tokens.\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  ]\n",
    "\n",
    "targetname='DemoOpenAPITargetS3Intrinio'\n",
    "response = gateway_client.create_gateway_target(\n",
    "    gatewayIdentifier=gateway_id,\n",
    "    name=targetname,\n",
    "    description='OpenAPI Target with S3Uri using SDK',\n",
    "    targetConfiguration=Intrinio_openapi_s3_target_config,\n",
    "    credentialProviderConfigurations=api_key_credential_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ac6532-5299-4024-917d-bcd60caea6ed",
   "metadata": {},
   "source": [
    "# Calling Bedrock AgentCore Gateway from a Strands Agent\n",
    "\n",
    "The Strands agent seamlessly integrates with AWS tools through the Bedrock AgentCore Gateway, which implements the Model Context Protocol (MCP) specification. This integration enables secure, standardized communication between AI agents and AWS services.\n",
    "\n",
    "At its core, the Bedrock AgentCore Gateway serves as a protocol-compliant Gateway that exposes fundamental MCP APIs: ListTools and InvokeTools. These APIs allow any MCP-compliant client or SDK to discover and interact with available tools in a secure, standardized way. When the Strands agent needs to access AWS services, it communicates with the Gateway using these MCP-standardized endpoints.\n",
    "\n",
    "The Gateway's implementation adheres strictly to the (MCP Authorization specification)[https://modelcontextprotocol.org/specification/draft/basic/authorization], ensuring robust security and access control. This means that every tool invocation by the Strands agent goes through authorization step, maintaining security while enabling powerful functionality.\n",
    "\n",
    "For example, when the Strands agent needs to access MCP tools, it first calls ListTools to discover available tools, then uses InvokeTools to execute specific actions. The Gateway handles all the necessary security validations, protocol translations, and service interactions, making the entire process seamless and secure.\n",
    "\n",
    "This architectural approach means that any client or SDK that implements the MCP specification can interact with AWS services through the Gateway, making it a versatile and future-proof solution for AI agent integrations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873031fe-62b5-4196-91be-500c1f87dfd4",
   "metadata": {},
   "source": [
    "# Request the access token from Amazon Cognito for inbound authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bddd9ea-0a3a-4d41-8ec9-dd2d93eed571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:16:29,011 - bedrock_agentcore.gateway - INFO - Fetching test token from Cognito...\n",
      "2025-09-12 16:16:29,014 - bedrock_agentcore.gateway - INFO -   Attempting to connect to token endpoint: https://agentcore-27cdb884.auth.us-west-2.amazoncognito.com/oauth2/token\n",
      "2025-09-12 16:16:29,425 - bedrock_agentcore.gateway - INFO - ✓ Got test token successfully\n"
     ]
    }
   ],
   "source": [
    "from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient\n",
    "\n",
    "# Initialize the Gateway client\n",
    "gateway_client_toolkit = GatewayClient(region_name=os.environ['AWS_DEFAULT_REGION'])\n",
    "# EZ Auth - automatically sets up Cognito OAuth\n",
    "access_token = gateway_client_toolkit.get_access_token_for_cognito(cognito_result[\"client_info\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd0379d-9576-43cb-aa9b-72b86c43b472",
   "metadata": {},
   "source": [
    "# Finance agent will use Bedrock AgentCore Gateway to retrive information from MCP tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be4b39c4-7387-4ce8-b728-f2347fbdaa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands.models import BedrockModel\n",
    "from mcp.client.streamable_http import streamablehttp_client \n",
    "from strands.tools.mcp.mcp_client import MCPClient\n",
    "from strands import Agent\n",
    "\n",
    "def create_streamable_http_transport():\n",
    "    return streamablehttp_client(gateway_url,headers={\"Authorization\": f\"Bearer {access_token}\"})\n",
    "\n",
    "mcp_client = MCPClient(create_streamable_http_transport)\n",
    "\n",
    "## The IAM group/user/ configured in ~/.aws/credentials should have access to Bedrock model\n",
    "yourmodel = BedrockModel(\n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e64794e7-4e5f-4fc5-824a-61c901e356c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | strands.telemetry.metrics | Creating Strands MetricsClient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools loaded in the agent are ['x_amz_bedrock_agentcore_search', 'DemoOpenAPITargetS3Intrinio___getCompany', 'DemoOpenAPITargetS3Intrinio___getCompanyFundamentals', 'DemoOpenAPITargetS3Intrinio___getHistoricalData']\n",
      "I can help you get company information for Nvidia. I'll use the appropriate tool to fetch this data for you.\n",
      "Tool #1: DemoOpenAPITargetS3Intrinio___getCompany\n",
      "Here is the company information for Nvidia:\n",
      "\n",
      "### Nvidia Corporation Overview\n",
      "\n",
      "**Basic Information:**\n",
      "- Ticker Symbol: NVDA\n",
      "- Full Name: NVIDIA CORP\n",
      "- Stock Exchange: Nasdaq\n",
      "- SIC Code: 3674\n",
      "- CEO: Jen H. Huang (Jensen Huang)\n",
      "\n",
      "**Business Description:**\n",
      "Nvidia Corporation provides graphics, compute, and networking solutions in the United States, Taiwan, China, and internationally. The company's products are used in gaming, professional visualization, datacenter, and automotive markets.\n",
      "\n",
      "**Key Business Segments:**\n",
      "1. **Graphics segment**: Offers GeForce GPUs for gaming and PCs, GeForce NOW game streaming service, Quadro/NVIDIA RTX GPUs for enterprise workstation graphics, and Omniverse software for 3D designs and virtual worlds.\n",
      "2. **Compute & Networking segment**: Provides Data Center platforms for AI and HPC, Mellanox networking solutions, automotive AI solutions, cryptocurrency mining processors, and Jetson for robotics.\n",
      "\n",
      "**Corporate Details:**\n",
      "- Founded: 1993\n",
      "- Headquarters: Santa Clara, California\n",
      "- Employees: 26,200\n",
      "- Website: nvidia.com\n",
      "- Business Address: 2788 SAN TOMAS EXPRESSWAY, SANTA CLARA, CA, 95051\n",
      "- Business Phone: 408-486-2000\n",
      "\n",
      "**Industry Classification:**\n",
      "- Sector: Manufacturing\n",
      "- Industry Category: Electronic Equipment\n",
      "- Industry Group: Electronic Components & Accessories\n",
      "- Legacy Sector: Technology\n",
      "- Legacy Industry Group: Semiconductor - Specialized\n",
      "\n",
      "**Company Status:** ACTIVEI can help you get financial information for Apple. I'll use the appropriate tool to fetch this data for you.\n",
      "Tool #2: DemoOpenAPITargetS3Intrinio___getCompanyFundamentals\n",
      "Now, let's get some specific financial data for Apple to provide you with more detailed information:\n",
      "Tool #3: DemoOpenAPITargetS3Intrinio___getHistoricalData\n",
      "Let's also get revenue information:\n",
      "Tool #4: DemoOpenAPITargetS3Intrinio___getHistoricalData\n",
      "Let's also check net income:\n",
      "Tool #5: DemoOpenAPITargetS3Intrinio___getHistoricalData\n",
      "# Apple Inc. (AAPL) Financial Overview\n",
      "\n",
      "## Company Information\n",
      "- **Ticker Symbol**: AAPL\n",
      "- **Full Name**: Apple Inc.\n",
      "- **CIK**: 0000320193\n",
      "- **LEI**: HWUPKR0MPOU8FGXBT394\n",
      "\n",
      "## Recent Financial Performance\n",
      "\n",
      "### Market Capitalization (Quarterly)\n",
      "- **June 2025**: $3.01 trillion\n",
      "- **March 2025**: $3.28 trillion\n",
      "- **December 2024**: $3.87 trillion\n",
      "- **September 2024**: $3.51 trillion\n",
      "- **June 2024**: $3.22 trillion\n",
      "\n",
      "### Total Revenue (Quarterly)\n",
      "- **June 2025**: $408.63 billion\n",
      "- **March 2025**: $400.37 billion\n",
      "- **December 2024**: $395.76 billion\n",
      "- **September 2024**: $391.04 billion\n",
      "- **June 2024**: $385.60 billion\n",
      "\n",
      "### Net Income (Quarterly)\n",
      "- **June 2025**: $99.28 billion\n",
      "- **March 2025**: $97.29 billion\n",
      "- **December 2024**: $96.15 billion\n",
      "- **September 2024**: $93.74 billion\n",
      "- **June 2024**: $101.96 billion\n",
      "\n",
      "## Financial Analysis\n",
      "Apple has maintained a strong market position with a market capitalization consistently above $3 trillion throughout 2024-2025. The company shows steady revenue growth quarter over quarter, with total revenue increasing from $385.60 billion in June 2024 to $408.63 billion in June 2025, representing approximately 6% year-over-year growth.\n",
      "\n",
      "Net income has remained robust, although there was a slight decrease from $101.96 billion in June 2024 to $99.28 billion in June 2025. Despite this small decline, Apple continues to demonstrate strong profitability with net income consistently above $93 billion per quarter.\n",
      "\n",
      "The company has extensive financial data available across multiple reporting periods, including income statements, balance sheets, and cash flow statements, indicating a well-established financial reporting structure and transparency for investors."
     ]
    }
   ],
   "source": [
    "from strands import Agent\n",
    "import logging\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT=\"You are a Financial Agent. You can use various tools available to you to get the financial and company information for a company\" \\\n",
    "\"Use the company name or ticker within the prompt and pass it as a required parametr or identifier to the tools. Identify the required parameters or identifiers\" \\\n",
    "\"Sometimes tag is a required parameter to the tool . use your judgement to derive a possible value for the tag from the prompt\" \n",
    "# Configure the root strands logger. Change it to DEBUG if you are debugging the issue\n",
    "logging.getLogger(\"strands\").setLevel(logging.INFO)\n",
    "\n",
    "# Add a handler to see the logs\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s | %(name)s | %(message)s\", \n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "with mcp_client:\n",
    "    # Call the listTools \n",
    "    tools = mcp_client.list_tools_sync()\n",
    "    # Create an Agent with the model and tools\n",
    "    agent = Agent(model=yourmodel,tools=tools, system_prompt=SYSTEM_PROMPT) ## you can replace with any model you like\n",
    "    print(f\"Tools loaded in the agent are {agent.tool_names}\")\n",
    "    # print(f\"Tools configuration in the agent are {agent.tool_config}\")\n",
    "    # Invoke the agent with the sample prompt. This will only invoke  MCP listTools and retrieve the list of tools the LLM has access to. The below does not actually call any tool.\n",
    "    # agent(\"Hi , can you list all tools available to you\")\n",
    "    agent(\"get company information for Nvidia\")\n",
    "    agent(\"get company financial information for Apple\")\n",
    "    # Invoke the agent with sample prompt, invoke the tool and display the response\n",
    "    #Call the MCP tool explicitly. The MCP Tool name and arguments must match with your AWS Lambda function or the OpenAPI/Smithy API\n",
    "    # result = client.call_tool_sync(\n",
    "    # tool_use_id=\"get-intrinio_tools_1\", # You can replace this with unique identifier. \n",
    "    # name=targetname+\"___getCompanyFundamentals\", # This is the tool name based on AWS Lambda target types. This will change based on the target name\n",
    "    # arguments={\"ver\": \"1.0\",\"feedtype\": \"json\"}\n",
    "    #)\n",
    "    #Print the MCP Tool response\n",
    "    #print(f\"Tool Call result: {result['content'][0]['text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37264f4-eeb0-4a69-a539-498a668669c5",
   "metadata": {},
   "source": [
    "# Strands Agents with AgentCore Memory (Short-Term Memory)\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates how to build a **personal agent** using Strands agents with AgentCore **short-term memory** (Raw events). The agent remembers recent conversations in the session using `get_last_k_turns` and can continue conversations seamlessly when user returns.\n",
    "\n",
    "\n",
    "### Tutorial Details\n",
    "\n",
    "| Information         | Details                                                                          |\n",
    "|:--------------------|:---------------------------------------------------------------------------------|\n",
    "| Tutorial type       | Short Term Conversational                                                        |\n",
    "| Agent type          | Personal Agent                                                                   |\n",
    "| Agentic Framework   | Strands Agents                                                                   |\n",
    "| LLM model           | Anthropic Claude Sonnet 3.7                                                      |\n",
    "| Tutorial components | AgentCore Short-term Memory, AgentInitializedEvent and MessageAddedEvent hooks   |\n",
    "| Example complexity  | Beginner                                                                         |\n",
    "\n",
    "You'll learn to:\n",
    "- Use short-term memory for conversation continuity\n",
    "- Retrieve last K conversation turns\n",
    "- Web search tool for real-time information\n",
    "- Initialize agents with conversation history\n",
    "\n",
    "## Architecture\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"architecture.png\" width=\"65%\" />\n",
    "</div>\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.10+\n",
    "- AWS credentials with AgentCore Memory permissions\n",
    "- AgentCore Memory role ARN\n",
    "- Access to Amazon Bedrock models\n",
    "\n",
    "Let's get started by setting up our environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c137c701-c05d-43ae-94b4-8efabb43f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"personal-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d89bbc2-6e5e-4175-9d25-a13cef62b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from strands.hooks import AgentInitializedEvent, HookProvider, HookRegistry, MessageAddedEvent\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "\n",
    "# Configuration\n",
    "REGION = os.getenv('AWS_REGION', 'us-east-1') # AWS region for the agent\n",
    "ACTOR_ID = \"user_123\" # It can be any unique identifier (AgentID, User ID, etc.)\n",
    "SESSION_ID = \"personal_session_001\" # Unique session identifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef09b444-1c62-4ad0-a994-7c29378ce7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "import uuid\n",
    "\n",
    "# Initialize Memory Client\n",
    "client = MemoryClient(region_name=REGION)\n",
    "memory_name = f\"PersonalAgentMemory_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "try:\n",
    "    # Create memory resource without strategies (thus only access to short-term memory)\n",
    "    memory = client.create_memory_and_wait(\n",
    "        name=memory_name,\n",
    "        strategies=[],  # No strategies for short-term memory\n",
    "        description=\"Short-term memory for personal agent\",\n",
    "        event_expiry_days=7, # Retention period for short-term memory. This can be upto 365 days.\n",
    "    )\n",
    "    memory_id = memory['id']\n",
    "    logger.info(f\"✅ Created memory: {memory_id}\")\n",
    "except ClientError as e:\n",
    "    logger.info(f\"❌ ERROR: {e}\")\n",
    "    if e.response['Error']['Code'] == 'ValidationException' and \"already exists\" in str(e):\n",
    "        # If memory already exists, retrieve its ID\n",
    "        memories = client.list_memories()\n",
    "        memory_id = next((m['id'] for m in memories if m['id'].startswith(memory_name)), None)\n",
    "        logger.info(f\"Memory already exists. Using existing memory ID: {memory_id}\")\n",
    "except Exception as e:\n",
    "    # Show any errors during memory creation\n",
    "    logger.error(f\"❌ ERROR: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    # Cleanup on error - delete the memory if it was partially created\n",
    "    if memory_id:\n",
    "        try:\n",
    "            client.delete_memory_and_wait(memory_id=memory_id)\n",
    "            logger.info(f\"Cleaned up memory: {memory_id}\")\n",
    "        except Exception as cleanup_error:\n",
    "            logger.error(f\"Failed to clean up memory: {cleanup_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "951f1411-295f-4d2b-b7de-c0fbab00637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryHookProvider(HookProvider):\n",
    "    def __init__(self, memory_client: MemoryClient, memory_id: str, actor_id: str, session_id: str):\n",
    "        self.memory_client = memory_client\n",
    "        self.memory_id = memory_id\n",
    "        self.actor_id = actor_id\n",
    "        self.session_id = session_id\n",
    "    \n",
    "    def on_agent_initialized(self, event: AgentInitializedEvent):\n",
    "        \"\"\"Load recent conversation history when agent starts\"\"\"\n",
    "        try:\n",
    "            # Load the last 5 conversation turns from memory\n",
    "            recent_turns = self.memory_client.get_last_k_turns(\n",
    "                memory_id=self.memory_id,\n",
    "                actor_id=self.actor_id,\n",
    "                session_id=self.session_id,\n",
    "                k=5\n",
    "            )\n",
    "            \n",
    "            if recent_turns:\n",
    "                # Format conversation history for context\n",
    "                context_messages = []\n",
    "                for turn in recent_turns:\n",
    "                    for message in turn:\n",
    "                        role = message['role']\n",
    "                        content = message['content']['text']\n",
    "                        context_messages.append(f\"{role}: {content}\")\n",
    "                \n",
    "                context = \"\\n\".join(context_messages)\n",
    "                # Add context to agent's system prompt.\n",
    "                event.agent.system_prompt += f\"\\n\\nRecent conversation:\\n{context}\"\n",
    "                logger.info(f\"✅ Loaded {len(recent_turns)} conversation turns\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Memory load error: {e}\")\n",
    "    \n",
    "    def on_message_added(self, event: MessageAddedEvent):\n",
    "        \"\"\"Store messages in memory\"\"\"\n",
    "        messages = event.agent.messages\n",
    "        try:\n",
    "            self.memory_client.create_event(\n",
    "                memory_id=self.memory_id,\n",
    "                actor_id=self.actor_id,\n",
    "                session_id=self.session_id,\n",
    "                messages=[(str(messages[-1].get(\"content\", \"\")), messages[-1][\"role\"])]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Memory save error: {e}\")\n",
    "    \n",
    "    def register_hooks(self, registry: HookRegistry):\n",
    "        # Register memory hooks\n",
    "        registry.add_callback(MessageAddedEvent, self.on_message_added)\n",
    "        registry.add_callback(AgentInitializedEvent, self.on_agent_initialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aea867c7-a440-49fa-a3b3-9492132f21d6",
   "metadata": {},
   "outputs": [],
   "source": [
    " with mcp_client:\n",
    "     tools = mcp_client.list_tools_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3627017-5398-4cd6-af1d-b99b9bc4b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_personal_agent():\n",
    "    \"\"\"Create personal agent with memory and web search\"\"\"\n",
    "    agent = Agent(\n",
    "        name=\"PersonalAssistant\",\n",
    "        model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",  # or your preferred model\n",
    "        system_prompt=f\"\"\" You are a Financial Agent. You can use various tools available to you to get the financial and company information for a company\n",
    "Use the company name or ticker within the prompt and pass it as a required parametr or identifier to the tools. Identify the required parameters or identifiers\n",
    "Sometimes tag is a required parameter to the tool . use your judgement to derive a possible value for the tag from the prompt\n",
    "        \n",
    "       \n",
    "        \n",
    "       \n",
    "        Today's date: {datetime.today().strftime('%Y-%m-%d')}\n",
    "        Be friendly and professional.\"\"\",\n",
    "        hooks=[MemoryHookProvider(client, memory_id, ACTOR_ID, SESSION_ID)],\n",
    "        tools=tools,\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "# Create agent\n",
    "agent = create_personal_agent()\n",
    "logger.info(\"✅ Personal agent created with memory and web search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b92f03d-bb78-4b86-a103-2f140e8331b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Alex! Since you're particularly interested in machine learning applications, let me focus on IBM's activities in this area. IBM has a strong presence in machine learning and artificial intelligence. Let me gather some more detailed information about the company that highlights these aspects.\n",
      "Tool #5: DemoOpenAPITargetS3Intrinio___getCompanyFundamentals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR | bedrock_agentcore.memory.client | Failed to create event: An error occurred (ValidationException) when calling the CreateEvent operation: 1 validation error detected: Value at 'payload.1.member.conversational.content.text' failed to satisfy constraint: Member must have length less than or equal to 9000\n",
      "ERROR | personal-agent | Memory save error: An error occurred (ValidationException) when calling the CreateEvent operation: 1 validation error detected: Value at 'payload.1.member.conversational.content.text' failed to satisfy constraint: Member must have length less than or equal to 9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, let me also look at some historical financial data that might give us insights into IBM's investment in machine learning and AI:\n",
      "Tool #6: DemoOpenAPITargetS3Intrinio___getHistoricalData\n",
      "Based on the information gathered, here's a comprehensive overview of IBM's machine learning applications and AI initiatives, which I think will interest you, Alex:\n",
      "\n",
      "# IBM's Machine Learning and AI Capabilities\n",
      "\n",
      "## Core AI and ML Offerings\n",
      "\n",
      "### 1. IBM Watson\n",
      "IBM's flagship AI platform includes:\n",
      "- **Watson Studio**: A collaborative environment for data scientists, developers, and domain experts to build, train, and deploy ML models\n",
      "- **Watson Machine Learning**: Cloud-based service that helps deploy and manage ML models at scale\n",
      "- **Watson Discovery**: Uses ML algorithms to analyze unstructured data, extracting insights from text, images, and audio\n",
      "- **Watson Assistant**: Conversational AI platform that uses ML to understand natural language queries\n",
      "\n",
      "### 2. Software Segment AI Integration\n",
      "As highlighted in the company information, IBM's Software segment offers:\n",
      "- **AI Operations (AIOps)**: Using ML to automate IT operations\n",
      "- **Data and artificial intelligence solutions**: Enterprise-grade ML and AI tools\n",
      "- **Hybrid cloud platform solutions**: Integrating AI capabilities across cloud environments\n",
      "\n",
      "### 3. Research and Innovation\n",
      "IBM Research continues to be at the forefront of ML research with:\n",
      "- Quantum computing applications for ML\n",
      "- Foundation models and large language models (LLMs)\n",
      "- Explainable AI initiatives\n",
      "- Federated learning for privacy-preserving ML\n",
      "\n",
      "## Industry Applications\n",
      "\n",
      "IBM has applied machine learning across numerous sectors:\n",
      "\n",
      "### Healthcare\n",
      "- Medical imaging analysis and diagnostics\n",
      "- Drug discovery acceleration\n",
      "- Clinical decision support systems\n",
      "- Health data analytics\n",
      "\n",
      "### Financial Services\n",
      "- Risk assessment and fraud detection\n",
      "- Algorithmic trading\n",
      "- Customer behavior analysis\n",
      "- Anti-money laundering applications\n",
      "\n",
      "### Manufacturing\n",
      "- Predictive maintenance\n",
      "- Quality control automation\n",
      "- Supply chain optimization\n",
      "- Process automation\n",
      "\n",
      "### Climate and Sustainability\n",
      "- Climate modeling\n",
      "- Energy optimization\n",
      "- Environmental monitoring\n",
      "- Sustainable resource management\n",
      "\n",
      "## Strategic Direction\n",
      "\n",
      "Under CEO Arvind Krishna's leadership, IBM has:\n",
      "1. **Focused on hybrid cloud and AI**: Positioned these as the company's core growth engines\n",
      "2. **Acquired Red Hat**: Strengthened open-source capabilities for AI/ML deployment\n",
      "3. **Invested in research**: Continued fundamental research in ML algorithms and applications\n",
      "4. **Developed vertical solutions**: Created industry-specific ML applications\n",
      "5. **Partnered with academic institutions**: To advance ML research and application\n",
      "\n",
      "## Financial Performance\n",
      "\n",
      "The financial data shows steady revenue growth:\n",
      "- Q2 2025: $64.039 billion\n",
      "- Q1 2025: $62.832 billion\n",
      "- Q4 2024: $62.753 billion\n",
      "\n",
      "This trend suggests continued investment in and client adoption of IBM's technology solutions, including their ML offerings.\n",
      "\n",
      "## Recent Developments\n",
      "\n",
      "- **Foundation Models**: IBM has been developing enterprise-grade foundation models designed for business applications\n",
      "- **Responsible AI**: Strong focus on ethical AI development and governance frameworks\n",
      "- **Edge ML**: Deploying machine learning capabilities at the edge for real-time processing\n",
      "- **AI Automation**: Using ML to automate business processes across industries\n",
      "\n",
      "Would you like me to explore any specific aspect of IBM's machine learning applications in more detail, Alex?"
     ]
    }
   ],
   "source": [
    "with mcp_client:\n",
    "#    agent(\"get company information for Nvidia\")\n",
    "#   agent(\"My name is Alex and I'm interested in learning about company IBM.\")\n",
    "    agent(\"I'm particularly interested in machine learning applications.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6169f9d2-6164-41ef-84cf-e923ea05f14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== User Returns - New Session ===\n",
      "User: What was my name again?\n",
      "Agent: Looking at our conversation, I can see that your name is Alex. You mentioned this when you first introduced yourself saying \"My name is Alex and I'm interested in learning about company IBM.\" I've been addressing you as Alex throughout our conversation about IBM's machine learning applications and company information.\n",
      "\n",
      "Is there something specific about IBM or another company you'd like to know more about?User: What was my last question?\n",
      "Agent: Your last question was about machine learning applications. Specifically, you said:\n",
      "\n",
      "\"I'm particularly interested in machine learning applications.\"\n",
      "\n",
      "After that, I provided information about IBM's machine learning and AI capabilities, including their Watson platform, software segment AI integration, research initiatives, and industry applications across healthcare, financial services, manufacturing, and climate/sustainability sectors.\n",
      "\n",
      "Is there a specific aspect of machine learning applications you'd like to explore further?"
     ]
    }
   ],
   "source": [
    " # Create new agent instance (simulates user returning)\n",
    "print(\"=== User Returns - New Session ===\")\n",
    "new_agent = create_personal_agent()\n",
    "\n",
    "# Test memory continuity\n",
    "print(f\"User: What was my name again?\")\n",
    "print(f\"Agent: \", end=\"\")\n",
    "with mcp_client:\n",
    "    new_agent(\"What was my name again?\")\n",
    "\n",
    "    print(f\"User: What was my last question?\")\n",
    "    print(f\"Agent: \", end=\"\")\n",
    "    new_agent(\"what was my last question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1c79a06-cd77-4169-8c24-831b73fc8aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PersonalAgentMemory_39708ddc-xDWoJW5t9l'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ba5d6-ce21-43b5-9c5d-7b78ea40cc2b",
   "metadata": {},
   "source": [
    "## View Stored Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04c80dc1-015a-443e-a15c-b28b33116f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Memory Contents ===\n"
     ]
    }
   ],
   "source": [
    "# Check what's stored in memory\n",
    "print(\"=== Memory Contents ===\")\n",
    "recent_turns = client.get_last_k_turns(\n",
    "    memory_id=memory_id,\n",
    "    actor_id=ACTOR_ID,\n",
    "    session_id=SESSION_ID,\n",
    "    k=3 # Adjust k to see more or fewer turns\n",
    ")\n",
    "\n",
    "for i, turn in enumerate(recent_turns, 1):\n",
    "    print(f\"Turn {i}:\")\n",
    "    for message in turn:\n",
    "        role = message['role']\n",
    "        content = message['content']['text'][:100] + \"...\" if len(message['content']['text']) > 100 else message['content']['text']\n",
    "        print(f\"  {role}: {content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8dd91d-15a6-45b2-b539-bb3eaf0e0e08",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "Additional resources are also created like IAM role, IAM Policies, Credentials provider, AWS Lambda functions, Cognito user pools, s3 buckets that you might need to manually delete as part of the clean up. This depends on the example you run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f158d-83b6-4d65-892f-9a208af3d742",
   "metadata": {},
   "source": [
    "## Delete the gateway (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58d250fc-dd34-4eb3-8d5b-c9eac9de9c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all targets for gateway testgatewayce61ef79-z61nbl7wbr\n",
      "Deleting target  I6R9NCQUJX\n",
      "Deleting gateway  testgatewayce61ef79-z61nbl7wbr\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "utils.delete_gateway(gateway_client,gateway_id)\n",
    "client.delete_memory_and_wait(memory_id)\n",
    "logger.info(f\"✅ Deleted memory: {memory_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd896b81-8c6d-4808-85b7-e33c5fa0b14c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
